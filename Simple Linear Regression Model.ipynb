{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression using numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "#import the relevant libraries.\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random input data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# declare a variable containing the size of the training set we want to generate.\n",
    "observations = 1000\n",
    "\n",
    "# We will work with two variables as inputs x and z.\n",
    "# We generate them randomly, drawing from an uniform distribution. There are 3 arguments of this method (low, high, size).\n",
    "# The size of xs and zs is observations divided by 1. In this case: 1000 x 1.\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
    "zs = np.random.uniform(-10, 10, (observations,1))\n",
    "\n",
    "# Combine the two dimensions of the input into one input matrix of size(1000,2). \n",
    "# This is the X matrix from the linear model y = x*w1 + z*w2 + b.\n",
    "# column_stack is a Numpy method, which combines two vectors(here,input vectors) into a matrix.\n",
    "inputs = np.column_stack((xs,zs))\n",
    "\n",
    "# Size of input matrix should be n x k, where n is the number of observations, and k is the number of variables, so 1000 x 2.\n",
    "print (inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the targets to aim at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# We want to \"make up\" a function, use the ML methodology, and see if the algorithm has learned it.\n",
    "# A small random noise is added to the function i.e. f(x,z) = 2x - 3z + 5 + <small noise>\n",
    "# Real datasets do have noises.\n",
    "noise = np.random.uniform(-1, 1, (observations,1))\n",
    "\n",
    "# Produce the targets according to the f(x,z) = 2x - 3z + 5 + noise .\n",
    "# In this way, the weights should be 2 and -3, while the bias is 5.\n",
    "targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "# The shape of the targets should be n x m, where m is the number of output variables, so 1000 x 1.\n",
    "print (targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08076164]\n",
      " [0.02481376]]\n",
      "[-0.02652211]\n"
     ]
    }
   ],
   "source": [
    "# Initializing the weights and biases randomly in some small initial range.\n",
    "# High initial ranges may prevent the machine learning algorithm from learning.\n",
    "init_range = 0.1\n",
    "\n",
    "# Weights are of size k x m, where k is the number of input variables and m is the number of output variables\n",
    "weights = np.random.uniform(low=-init_range, high=init_range, size=(2, 1))\n",
    "\n",
    "# Biases are of size 1 since there is only 1 output. The bias is a scalar.\n",
    "biases = np.random.uniform(low=-init_range, high=init_range, size=1)\n",
    "\n",
    "#Print the weights to get a sense of how they were initialized.\n",
    "print (weights)\n",
    "print (biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some small learning rate. \n",
    "learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230.55175303840124\n",
      "35.39575428516467\n",
      "14.213772557940082\n",
      "11.54651532154471\n",
      "10.870434098753647\n",
      "10.42286842356647\n",
      "10.014657802795499\n",
      "9.62492275721174\n",
      "9.25085408259661\n",
      "8.891608014159138\n",
      "8.546574056247817\n",
      "8.215187457872183\n",
      "7.8969081439077184\n",
      "7.591217654343766\n",
      "7.297618063249291\n",
      "7.0156311420304025\n",
      "6.744797577673858\n",
      "6.48467622429267\n",
      "6.234843384534644\n",
      "5.994892119441442\n",
      "5.764431585607713\n",
      "5.543086398557766\n",
      "5.330496021302439\n",
      "5.126314177080257\n",
      "4.930208285326275\n",
      "4.741858919949903\n",
      "4.560959289039345\n",
      "4.387214735145132\n",
      "4.220342255328819\n",
      "4.0600700401951055\n",
      "3.906137031156446\n",
      "3.758292495209109\n",
      "3.6162956165279794\n",
      "3.479915104214928\n",
      "3.3489288155617905\n",
      "3.22312339421436\n",
      "3.1022939226479376\n",
      "2.9862435883884837\n",
      "2.8747833634356055\n",
      "2.7677316963652525\n",
      "2.6649142166105992\n",
      "2.566163450439429\n",
      "2.4713185481653848\n",
      "2.3802250221487857\n",
      "2.2927344951602016\n",
      "2.208704458696957\n",
      "2.1279980408588823\n",
      "2.050483783405203\n",
      "1.976035427629454\n",
      "1.9045317087036213\n",
      "1.8358561581565427\n",
      "1.7698969141648186\n",
      "1.706546539347262\n",
      "1.6457018457660462\n",
      "1.5872637268495657\n",
      "1.5311369959631953\n",
      "1.4772302313650127\n",
      "1.4254556272939702\n",
      "1.3757288509479186\n",
      "1.3279689051185428\n",
      "1.2820979962594774\n",
      "1.238041407772677\n",
      "1.1957273783066633\n",
      "1.1550869848684142\n",
      "1.1160540305584896\n",
      "1.0785649367465504\n",
      "1.0425586395116233\n",
      "1.0079764901784514\n",
      "0.9747621597878828\n",
      "0.9428615473457408\n",
      "0.912222691700684\n",
      "0.8827956869075597\n",
      "0.8545326009383434\n",
      "0.8273873976083096\n",
      "0.8013158615902157\n",
      "0.7762755263943951\n",
      "0.7522256051974263\n",
      "0.7291269244067271\n",
      "0.7069418598528403\n",
      "0.6856342755054998\n",
      "0.6651694646136391\n",
      "0.6455140931734743\n",
      "0.6266361456325803\n",
      "0.6085048727415208\n",
      "0.591090741468093\n",
      "0.5743653868925874\n",
      "0.558301566005741\n",
      "0.5428731133340964\n",
      "0.5280548983204983\n",
      "0.5138227843903215\n",
      "0.5001535896367236\n",
      "0.4870250490609211\n",
      "0.47441577830595366\n",
      "0.46230523882488417\n",
      "0.45067370442669097\n",
      "0.43950222914535847\n",
      "0.4287726163798405\n",
      "0.41846738925461646\n",
      "0.4085697621525695\n",
      "0.39906361337382085\n"
     ]
    }
   ],
   "source": [
    "# Iterate over our training dataset 100 times.\n",
    "# a lower learning rate would need more iterations, while a higher learning rate would need less iterations\n",
    "# a high learning rate may cause the loss to diverge to infinity, instead of converge to 0.\n",
    "for i in range (100):\n",
    "    \n",
    "    # This is the linear model: y = xw + b equation\n",
    "    outputs = np.dot(inputs,weights) + biases\n",
    "    # The deltas are the differences between the outputs and the targets\n",
    "    # deltas here is a vector 1000 x 1\n",
    "    deltas = outputs - targets\n",
    "        \n",
    "    # We are considering the L2-norm loss, but divided by 2.\n",
    "    # Moreover, we further divide it by the number of observations.\n",
    "    # This is simple rescaling by a constant. This doesn't change the optimization logic.\n",
    "    loss = np.sum(deltas ** 2) / 2 / observations\n",
    "    \n",
    "    # Print the loss function value at each step to observe whether it is decreasing as desired.\n",
    "    print (loss)\n",
    "    \n",
    "    # Scale the deltas the same way as the loss function.\n",
    "    # In this way the learning rate is independent of the number of samples (observations).\n",
    "    # Again, this doesn't change anything in principle, it simply makes it easier to pick a single learning rate.\n",
    "    # that can remain the same if we change the number of training samples (observations).\n",
    "    deltas_scaled = deltas / observations\n",
    "    \n",
    "    # Finally, apply the gradient descent update rules.\n",
    "    # The weights are 2x1, learning rate is 1x1 (scalar), inputs are 1000x2, and deltas_scaled are 1000x1\n",
    "    # We must transpose the inputs so as to get an allowed operation.\n",
    "    weights = weights - learning_rate * np.dot(inputs.T,deltas_scaled)\n",
    "    biases = biases - learning_rate * np.sum(deltas_scaled)\n",
    "    \n",
    "    # The weights and biases are updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print weights and biases and see if it worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.99487654]\n",
      " [-3.00053336]] [4.33218376]\n"
     ]
    }
   ],
   "source": [
    "# Print the weights and the biases to see if they have converged to what we wanted.\n",
    "# When declared the targets, following the f(x,z), we knew the weights should be 2 and -3, while the bias: 5.\n",
    "print (weights, biases)\n",
    "\n",
    "# Note that they may be convergING. So more iterations are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot last outputs vs targets\n",
    "Since they are the last ones at the end of the training, they represent the final model accuracy. <br/>\n",
    "The closer this plot is to a 45 degree line, the closer target and output values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the outputs and the targets in order to see if they have a linear relationship.\n",
    "\n",
    "plt.plot(outputs,targets)\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
