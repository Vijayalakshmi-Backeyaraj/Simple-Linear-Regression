{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import the relevant libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "\n",
    "Data is generated and stored to an npz file. Npz is numpy's file type which allows us to save numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a variable containing the size of the training set you want to generate.\n",
    "observations = 1000\n",
    "# x and z are the inputs.\n",
    "# They are generated randomly, drawing from an uniform distribution. There are 3 arguments of this method (low, high, size).\n",
    "# The size of xs and zs is observations x 1. In this case: 1000 x 1.\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
    "zs = np.random.uniform(-10, 10, (observations,1))\n",
    "\n",
    "# Combine the two dimensions of the input into one input matrix. \n",
    "# column_stack is a Numpy method, which combines two matrices (vectors) into one.\n",
    "generated_inputs = np.column_stack((xs,zs))\n",
    "\n",
    "# A random small noise is added to the function i.e. f(x,z) = 2x - 3z + 5 + <small noise>\n",
    "noise = np.random.uniform(-1, 1, (observations,1))\n",
    "\n",
    "# Produce the targets according to  f(x,z) = 2x - 3z + 5 + noise .\n",
    "# In this way, we are basically saying: the weights should be 2 and -3, while the bias is 5.\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "# save into an npz file called \"TF_intro\"\n",
    "np.savez('TF_intro', inputs=generated_inputs, targets=generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape of the data we've prepared above. They can also be called as number of inputs, number of outputs.\n",
    "input_size = 2\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic TensorFlow object - the placeholder.\n",
    "# We have to feed the inputs and targets to the model. \n",
    "# In the TensorFlow context, we feed the data to the model THROUGH the placeholders. \n",
    "# The  inputs and targets are contained in the above generated .npz file.\n",
    "\n",
    "# The first None parameter of the placeholders' shape means that\n",
    "# this dimension could be of any length. That's since we are mainly interested in\n",
    "# the input size, i.e. how many input variables we have and not the number of samples (observations)\n",
    "# The number of input variables changes the MODEL itself, while the number of observations doesn't.\n",
    "# The weights and biases were independent of the number of samples, so the MODEL is independent of samples.\n",
    "# Until this point, we've only fed the data to the model and no operation has occured yet.\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size])\n",
    "targets = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "# Define the weights and biases.\n",
    "# Basic TensorFlow object - a variable.\n",
    "# Data has to be fed into placeholders and they have a different value for each iteration\n",
    "# Variables, however, preserve their values across iterations.\n",
    "# To sum up, data goes into placeholders; parameters go into variables.\n",
    "# Use the random uniform initialization in [-0.1,0.1] to initialise the variables.\n",
    "# Until this point, no operation has occured.\n",
    "\n",
    "weights = tf.Variable(tf.random_uniform([input_size, output_size], minval=-0.1, maxval=0.1))\n",
    "biases = tf.Variable(tf.random_uniform([output_size], minval=-0.1, maxval=0.1))\n",
    "\n",
    "# Outputs follow the linear combination: y = xw + b\n",
    "# This line simply tells TensorFlow what rule to apply when we feed in the training data (below).\n",
    "outputs = tf.matmul(inputs, weights) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the objective function and the optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sangeethabackeyaraj\\anaconda3\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Use the readily available loss function, mean_squared_error which is the scaled L2-norm (per observation)\n",
    "# We divide by two to implement a L2-norm/2 loss. That doesn't really change anything.\n",
    "mean_loss = tf.losses.mean_squared_error(labels=targets, predictions=outputs) / 2.\n",
    "\n",
    "# There also exists a function tf.nn.l2_loss. \n",
    "# tf.nn.l2_loss calculates the loss over all samples, instead of the average loss per sample.\n",
    "# Practically it's the same, the difference would be a smaller or larger learning rate to achieve the exact same result. \n",
    "\n",
    "# Instead of implementing Gradient Descent on our own, in TensorFlow we can simply state\n",
    "# \"Minimize the mean loss by using Gradient Descent with a given learning rate\"\n",
    "optimize = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've defined the placeholders, variables, the loss function and the optimization method.\n",
    "# The structure for training is complete, but we haven't trained anything yet.\n",
    "# The actual training (and subsequent implementation of the ML algorithm) happens inside sessions.\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start training, we need to initialize our variables: the weights and biases.\n",
    "# There is a specific method for initializing called global_variables_initializer().\n",
    "# Let's declare a variable \"initializer\" that will do that.\n",
    "initializer = tf.global_variables_initializer()\n",
    "\n",
    "# Using sess.run function to initialize the variables.\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally load the training data we created above.\n",
    "training_data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.06335\n",
      "115.36617\n",
      "62.21644\n",
      "35.25274\n",
      "21.38471\n",
      "14.092774\n",
      "10.122037\n",
      "7.8437014\n",
      "6.4405746\n",
      "5.5011277\n",
      "4.816926\n",
      "4.28137\n",
      "3.839056\n",
      "3.4604027\n",
      "3.128943\n",
      "2.834938\n",
      "2.5721598\n",
      "2.336277\n",
      "2.124023\n",
      "1.9327713\n",
      "1.7603141\n",
      "1.604739\n",
      "1.4643608\n",
      "1.3376777\n",
      "1.2233467\n",
      "1.1201586\n",
      "1.0270251\n",
      "0.94296634\n",
      "0.8670969\n",
      "0.7986187\n",
      "0.7368112\n",
      "0.68102556\n",
      "0.6306739\n",
      "0.5852278\n",
      "0.5442091\n",
      "0.50718594\n",
      "0.4737696\n",
      "0.44360903\n",
      "0.41638622\n",
      "0.39181527\n",
      "0.3696383\n",
      "0.3496216\n",
      "0.331555\n",
      "0.31524834\n",
      "0.30053002\n",
      "0.28724563\n",
      "0.27525568\n",
      "0.2644334\n",
      "0.25466564\n",
      "0.24584939\n",
      "0.23789194\n",
      "0.23070969\n",
      "0.22422712\n",
      "0.21837603\n",
      "0.21309508\n",
      "0.20832853\n",
      "0.20402633\n",
      "0.20014319\n",
      "0.1966385\n",
      "0.19347496\n",
      "0.19061972\n",
      "0.18804273\n",
      "0.18571667\n",
      "0.18361725\n",
      "0.18172225\n",
      "0.18001199\n",
      "0.17846815\n",
      "0.1770749\n",
      "0.17581728\n",
      "0.17468216\n",
      "0.17365775\n",
      "0.1727331\n",
      "0.17189842\n",
      "0.17114519\n",
      "0.17046529\n",
      "0.16985154\n",
      "0.16929762\n",
      "0.16879775\n",
      "0.1683465\n",
      "0.16793922\n",
      "0.1675716\n",
      "0.16723986\n",
      "0.16694035\n",
      "0.16667004\n",
      "0.16642612\n",
      "0.16620588\n",
      "0.16600715\n",
      "0.16582777\n",
      "0.16566584\n",
      "0.16551968\n",
      "0.16538781\n",
      "0.16526876\n",
      "0.16516131\n",
      "0.16506433\n",
      "0.16497678\n",
      "0.1648978\n",
      "0.16482647\n",
      "0.16476211\n",
      "0.164704\n",
      "0.16465157\n"
     ]
    }
   ],
   "source": [
    "# Train for a set number (100) of iterations over the dataset.\n",
    "for i in range(100):\n",
    "\n",
    "    # sess.run is the session's function to actually do something, anything.\n",
    "    # Using sess.run to feed the training data to the computational graph, defined by the feed_dict parameter\n",
    "    # and run operations (already defined above), given as the first parameter (optimize, mean_loss).\n",
    "    # So the line of code means: \"Run the optimize and mean_loss operations by filling the placeholder\n",
    "    # objects with data from the feed_dict parameter\".\n",
    "    # Curr_loss catches the output from the two operations.\n",
    "    # Using \"_,\" we omit the first one, because optimize has no output (it's always \"None\"). \n",
    "    # The second one catches the value of the mean_loss for the current run, thus curr_loss actually = mean_loss \n",
    "    _, curr_loss = sess.run([optimize, mean_loss], \n",
    "        feed_dict={inputs: training_data['inputs'], targets: training_data['targets']})\n",
    "    \n",
    "    # Print the current average loss\n",
    "    print(curr_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the last output vs targets after the training is supposedly over. \n",
    "# we need the outputs. Therefore, instead of the optimize and mean_loss operations, pass the \"outputs\" as the only parameter.\n",
    "out = sess.run([outputs], \n",
    "               feed_dict={inputs: training_data['inputs']})\n",
    "# The model is optimized, so the outputs are calculated based on the last form of the model\n",
    "\n",
    "# np.squeeze squeezes the arrays in order to fit them to what the plot function expects.\n",
    "plt.plot(np.squeeze(out), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
